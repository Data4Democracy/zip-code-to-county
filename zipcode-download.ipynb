{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import glob\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def verify_dirs_exist():\n",
    "    #This notebook requires a few directories\n",
    "    dirs = [\"download\", \"download\\csv\", \"download\\excel\"]\n",
    "    for d in dirs:\n",
    "        curpath = os.path.abspath(os.curdir) # get current working directory\n",
    "        full_path = os.path.join(curpath, d) # join cwd with proposed d \n",
    "        create_dir_if_not_exists(full_path)\n",
    "        \n",
    "def create_dir_if_not_exists(full_path):\n",
    "    # expects a full path to the directory to test against or to create.\n",
    "    if not os.path.exists(full_path):\n",
    "        os.makedirs(full_path)\n",
    "        print(\"Created directory \", full_path)\n",
    "    else:\n",
    "        print(\"Directory \", full_path, \" already existed\")\n",
    "\n",
    "verify_dirs_exist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_file_name_from_url(url):\n",
    "    month_year = url.split(\"\\\\\")[-1].split(\"_\")[-1].split(\".\")[0] \n",
    "    month = month_year[:2]\n",
    "    year = month_year[2:]\n",
    "    new_file_name = \"ZIP-COUNTY-FIPS_\"+year + \"-\" + month\n",
    "    return new_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_file_path(url, csv_file=False):\n",
    "    \"Takes in the full url and returns the full file path\"\n",
    "    \"File names are ZIP_COUNTY_032010.xlsx\"\n",
    "    curpath = os.path.abspath(os.curdir) #get current working directory\n",
    "    full_path = ''\n",
    "    if csv_file:\n",
    "        #If we are passing in a csv, change xlsx to .csv\n",
    "        csv_file_name = url.split(\"\\\\\")[-1][:-5] + \".csv\"\n",
    "        full_path = os.path.join(curpath, \"download\\csv\", csv_file_name)\n",
    "    else:\n",
    "        url_name = url.split('/')[-1] # gets file name\n",
    "        #switching file names to be YYYY-MM for better file management\n",
    "        url_file_name = generate_file_name_from_url(url) + \".xlsx\"\n",
    "        full_path = os.path.join(curpath, \"download\\excel\", url_file_name)\n",
    "    return full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_file(url):\n",
    "    #With a full url, downloads the full file in chunks. \n",
    "    #Able to handle large files.\n",
    "    full_file_path = get_file_path(url)\n",
    "    r = requests.get(url)\n",
    "    with open(full_file_path, 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=1024): \n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)\n",
    "    return full_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census State & County FIPS Data\n",
    "HUD uses ZIP & FIPS data. We need to grab the FIPS to county name data to be able to merge and create the cross lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "census_fips_url = \"https://www2.census.gov/geo/docs/reference/codes/files/national_county.txt\"\n",
    "#the FIPS data does not come with column names\n",
    "census_col_names = [\"STATE\",\"STATEFP\",\"COUNTYFP\",\"COUNTYNAME\",\"CLASSFP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Open url, read in the data with the column names, and convert specific columns to str. \n",
    "# When Pandas reads these columns, it automatilcally intrepets them as INTS \n",
    "fips_df = pd.read_table(\n",
    "    census_fips_url, \n",
    "    sep=\",\", \n",
    "    names=census_col_names, \n",
    "    converters={'STATEFP': str,'COUNTYFP': str,'CLASSFP': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine State & County FP to generate the full FIPS code for easier lookup\n",
    "fips_df[\"STCOUNTYFP\"] = fips_df[\"STATEFP\"] + fips_df[\"COUNTYFP\"]\n",
    "#Dropping STATFP & COUNTYFP as we no longer need them\n",
    "fips_df = fips_df[[\"STCOUNTYFP\", \"STATE\" ,\"COUNTYNAME\", \"CLASSFP\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get current year to handle future runs of this file\n",
    "now = dt.datetime.now()\n",
    "cur_year = now.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_files_url(month, year):\n",
    "    monthyear = month + str(year) \n",
    "    return \"https://www.huduser.gov/portal/datasets/usps/ZIP_COUNTY_{}.xlsx\".format(monthyear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_excel_file(full_excel_path):\n",
    "    # takes in the excel file and returns the needed data in a dataframe\n",
    "    # grab download excel file and load as pandas DF\n",
    "    excel_df = pd.read_excel(full_excel_path, index_col=None, converters={'ZIP': str, 'COUNTY': str})\n",
    "    # rename County column for easier merging.\n",
    "    excel_df.rename(columns={\"COUNTY\":\"STCOUNTYFP\"}, inplace=True)\n",
    "    # keep the two columns we need \n",
    "    return excel_df[[\"ZIP\", \"STCOUNTYFP\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_dfs(excel_df):\n",
    "    merged_df = fips.merge(excel_df)\n",
    "    return merged_df[[\"ZIP\", \"COUNTYNAME\", \"STATE\", \"STCOUNTYFP\", \"CLASSFP\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from the beginning of hud year data to current year\n",
    "for year in range(2010, cur_year+1):\n",
    "    #hud files are based on quarters\n",
    "    for month in [\"03\", \"06\", \"09\", \"12\"]:\n",
    "        #generate the HUDs url\n",
    "        url = get_files_url(month, year)\n",
    "        #download the file\n",
    "        full_file_path = download_file(url)\n",
    "        #open and get the excel dataframe\n",
    "        excel_df = process_excel_file(full_file_path)\n",
    "        #merge the excel file with the fips data\n",
    "        merged_df = fips_df.merge(excel_df)\n",
    "        #reduce the dataframe down to specific columns \n",
    "        merged_df = merged_df[[\"ZIP\", \"COUNTYNAME\", \"STATE\", \"STCOUNTYFP\", \"CLASSFP\"]] \n",
    "        #generate a csv file path\n",
    "        csv_path = get_file_path(full_file_path, True)\n",
    "        print(csv_path)\n",
    "        try:\n",
    "            merged_df.to_csv(csv_path, encoding='utf-8', index=False)\n",
    "        except:\n",
    "            #once we get to a Q that hasn't happened yet, we'll get an XLDRerror\n",
    "            print(\"Operation has completed\")\n",
    "            break\n",
    "        \n",
    "        # prevent from overloading the HUD site and to be a nice visitor\n",
    "        time.sleep(1)\n",
    "        print(\"Completed \", csv_path)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
